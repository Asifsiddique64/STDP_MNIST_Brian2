{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.cm as cmap\n",
    "import time\n",
    "import os.path\n",
    "import scipy \n",
    "import pickle\n",
    "from struct import unpack\n",
    "from brian2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#------------------------------------------------------------------------------ \n",
    "# functions\n",
    "#------------------------------------------------------------------------------     \n",
    "def get_labeled_data(picklename, bTrain = True):\n",
    "    \"\"\"Read input-vector (image) and target class (label, 0-9) and return\n",
    "       it as list of tuples.\n",
    "    \"\"\"\n",
    "    if os.path.isfile('%s.pickle' % picklename):\n",
    "        with open('%s.pickle' % picklename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "    else:\n",
    "        # Open the images with gzip in read binary mode\n",
    "        if bTrain:\n",
    "            images = open(MNIST_data_path + 'train-images.idx3-ubyte','rb')\n",
    "            labels = open(MNIST_data_path + 'train-labels.idx1-ubyte','rb')\n",
    "        else:\n",
    "            images = open(MNIST_data_path + 't10k-images.idx3-ubyte','rb')\n",
    "            labels = open(MNIST_data_path + 't10k-labels.idx1-ubyte','rb')\n",
    "        # Get metadata for images\n",
    "        images.read(4)  # skip the magic_number\n",
    "        number_of_images = unpack('>I', images.read(4))[0]\n",
    "        rows = unpack('>I', images.read(4))[0]\n",
    "        cols = unpack('>I', images.read(4))[0]\n",
    "        # Get metadata for labels\n",
    "        labels.read(4)  # skip the magic_number\n",
    "        N = unpack('>I', labels.read(4))[0]\n",
    "        if number_of_images != N:\n",
    "            raise Exception('number of labels did not match the number of images')\n",
    "        # Get the data\n",
    "        x = np.zeros((N, rows, cols), dtype=np.uint8)  # Initialize numpy array\n",
    "        y = np.zeros((N, 1), dtype=np.uint8)  # Initialize numpy array\n",
    "        for i in range(N):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"i: %i\" % i)\n",
    "            x[i] = [[unpack('>B', images.read(1))[0] for unused_col in range(cols)]  for unused_row in range(rows) ]\n",
    "            y[i] = unpack('>B', labels.read(1))[0]\n",
    "        data = {'x': x, 'y': y, 'rows': rows, 'cols': cols}\n",
    "        pickle.dump(data, open(\"%s.pickle\" % picklename, \"wb\"))\n",
    "    return data\n",
    "\n",
    "def get_recognized_number_ranking(assignments, spike_rates):\n",
    "    summed_rates = [0] * 10\n",
    "    num_assignments = [0] * 10\n",
    "    for i in range(10):\n",
    "        num_assignments[i] = len(np.where(assignments == i)[0])\n",
    "        if num_assignments[i] > 0:\n",
    "            summed_rates[i] = np.sum(spike_rates[assignments == i]) / num_assignments[i]\n",
    "    return np.argsort(summed_rates)[::-1]\n",
    "\n",
    "def get_new_assignments(result_monitor, input_numbers):\n",
    "    print (result_monitor.shape)\n",
    "    assignments = np.ones(n_e) * -1 # initialize them as not assigned\n",
    "    input_nums = np.asarray(input_numbers)\n",
    "    maximum_rate = [0] * n_e    \n",
    "    for j in range(10):\n",
    "        num_inputs = len(np.where(input_nums == j)[0])\n",
    "        if num_inputs > 0:\n",
    "            rate = np.sum(result_monitor[input_nums == j], axis = 0) / num_inputs\n",
    "        for i in range(n_e):\n",
    "            if rate[i] > maximum_rate[i]:\n",
    "                maximum_rate[i] = rate[i]\n",
    "                assignments[i] = j \n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_data_path = '/home/asif/lava-dl/Tasks/Task_7/Unsupervised_STDP/data/'\n",
    "data_path = '/home/asif/lava-dl/Tasks/Task_8/Brian2STDPMNIST/activity/'\n",
    "training_ending = '10000'\n",
    "testing_ending = '10000'\n",
    "start_time_training = 0\n",
    "end_time_training = int(training_ending)\n",
    "start_time_testing = 0\n",
    "end_time_testing = int(testing_ending)\n",
    "\n",
    "n_e = 400\n",
    "n_input = 784\n",
    "ending = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load MNIST\n"
     ]
    }
   ],
   "source": [
    "print('load MNIST')\n",
    "training = get_labeled_data(MNIST_data_path + 'training')\n",
    "testing = get_labeled_data(MNIST_data_path + 'testing', bTrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load results\n",
      "(10000, 400)\n"
     ]
    }
   ],
   "source": [
    "print ('load results')\n",
    "training_result_monitor = np.load(data_path + 'resultPopVecs' + training_ending + ending + '.npy')\n",
    "training_input_numbers = np.load(data_path + 'inputNumbers' + training_ending + '.npy')\n",
    "testing_result_monitor = np.load(data_path + 'resultPopVecs' + testing_ending + '.npy')\n",
    "testing_input_numbers = np.load(data_path + 'inputNumbers' + testing_ending + '.npy')\n",
    "print (training_result_monitor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get assignments\n",
      "(10000, 400)\n"
     ]
    }
   ],
   "source": [
    "print('get assignments')\n",
    "test_results = np.zeros((10, end_time_testing-start_time_testing))\n",
    "test_results_max = np.zeros((10, end_time_testing-start_time_testing))\n",
    "test_results_top = np.zeros((10, end_time_testing-start_time_testing))\n",
    "test_results_fixed = np.zeros((10, end_time_testing-start_time_testing))\n",
    "assignments = get_new_assignments(training_result_monitor[start_time_training:end_time_training], \n",
    "                                  training_input_numbers[start_time_training:end_time_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7. 3. 2. 2. 1. 5. 6. 2. 5. 0. 0. 3. 1. 4. 0. 2. 4. 7. 6. 3. 0. 0. 6. 8.\n",
      " 8. 2. 0. 2. 3. 1. 6. 6. 7. 5. 2. 9. 6. 0. 2. 3. 7. 2. 0. 3. 4. 3. 6. 2.\n",
      " 2. 2. 2. 8. 6. 6. 2. 6. 4. 7. 4. 0. 0. 8. 9. 8. 8. 2. 8. 6. 8. 9. 2. 3.\n",
      " 9. 2. 8. 1. 6. 7. 7. 6. 3. 5. 9. 8. 9. 6. 3. 6. 0. 4. 4. 1. 6. 2. 4. 6.\n",
      " 9. 3. 0. 5. 7. 0. 3. 3. 8. 3. 8. 1. 6. 8. 9. 9. 3. 2. 6. 5. 0. 3. 7. 1.\n",
      " 5. 6. 0. 0. 9. 2. 2. 5. 8. 3. 7. 8. 0. 6. 9. 0. 3. 9. 4. 4. 0. 4. 9. 4.\n",
      " 4. 8. 4. 0. 9. 3. 2. 7. 3. 3. 0. 9. 9. 0. 7. 0. 9. 6. 5. 0. 9. 8. 1. 4.\n",
      " 7. 7. 3. 2. 7. 8. 7. 1. 2. 7. 2. 4. 8. 3. 0. 1. 7. 9. 5. 8. 4. 5. 7. 6.\n",
      " 7. 2. 6. 5. 2. 9. 0. 6. 0. 0. 9. 2. 8. 3. 0. 3. 0. 4. 4. 0. 8. 6. 6. 3.\n",
      " 9. 0. 8. 7. 8. 5. 2. 0. 4. 6. 9. 9. 2. 3. 9. 8. 6. 1. 3. 5. 6. 6. 9. 8.\n",
      " 5. 3. 3. 2. 1. 9. 3. 6. 5. 2. 0. 8. 8. 9. 5. 0. 8. 3. 3. 1. 5. 1. 5. 0.\n",
      " 8. 2. 5. 9. 9. 4. 0. 2. 1. 3. 9. 6. 8. 5. 7. 7. 2. 4. 6. 0. 0. 3. 4. 2.\n",
      " 5. 8. 5. 6. 2. 8. 0. 0. 2. 7. 4. 2. 3. 4. 8. 8. 0. 3. 0. 9. 5. 7. 5. 5.\n",
      " 2. 6. 5. 0. 2. 8. 2. 4. 7. 1. 7. 8. 9. 4. 6. 6. 7. 6. 2. 6. 7. 0. 2. 5.\n",
      " 9. 9. 2. 6. 3. 3. 6. 0. 5. 6. 0. 0. 2. 3. 0. 3. 5. 7. 4. 9. 4. 8. 6. 1.\n",
      " 3. 5. 8. 1. 4. 0. 1. 0. 5. 0. 4. 8. 0. 9. 7. 3. 0. 5. 1. 5. 4. 7. 0. 3.\n",
      " 2. 7. 3. 3. 2. 1. 7. 0. 9. 0. 2. 3. 8. 9. 1. 8.]\n",
      "calculate accuracy for sum\n",
      "Sum response - accuracy:  91.42  num incorrect:  858\n",
      "Sum response - accuracy --> mean:  91.42 --> standard deviation:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(assignments)\n",
    "counter = 0 \n",
    "num_tests = end_time_testing / 10000\n",
    "sum_accurracy = [0] * int(num_tests)\n",
    "while (counter < num_tests):\n",
    "    end_time = min(end_time_testing, 10000*(counter+1))\n",
    "    start_time = 10000*counter\n",
    "    test_results = np.zeros((10, end_time-start_time))\n",
    "    print( 'calculate accuracy for sum')\n",
    "    for i in range(end_time - start_time):\n",
    "        test_results[:,i] = get_recognized_number_ranking(assignments, \n",
    "                                                          testing_result_monitor[i+start_time,:])\n",
    "    difference = test_results[0,:] - testing_input_numbers[start_time:end_time]\n",
    "    correct = len(np.where(difference == 0)[0])\n",
    "    incorrect = np.where(difference != 0)[0]\n",
    "    sum_accurracy[counter] = correct/float(end_time-start_time) * 100\n",
    "    print ('Sum response - accuracy: ', sum_accurracy[counter], ' num incorrect: ', len(incorrect))\n",
    "    counter += 1\n",
    "print ('Sum response - accuracy --> mean: ', np.mean(sum_accurracy),  '--> standard deviation: ', np.std(sum_accurracy))\n",
    "\n",
    "\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a272f5b702f779b251db55d93fb89e1490bb3a01ba35db471070dd85d48224b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
